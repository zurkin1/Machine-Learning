{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('c:/Users/dani/PycharmProjects/WOW/CSV/TCUSTCOUPONITEMSSPENT.csv', index_col=None)\n",
    "data = data.loc[(data.ACCOUNT_CODE == 10869649) & (data.DEAL_CODE == 20) & (data.COUPON_CODE == 2158)]\n",
    "data.to_csv('User10869649.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('User10869649.csv')\n",
    "d = \"2013-W26\"\n",
    "import datetime\n",
    "data['datestr'] = data[['YEARIND', 'WEEKIND']].apply(lambda x: '20{}-W{}-0'.format(x.YEARIND, x.WEEKIND), axis=1)\n",
    "data['date'] = pd.to_datetime(data.datestr , format='%Y-W%W-%w')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = pd.read_csv('User10869649.csv', index_col=0).reset_index(drop=True)\n",
    "data2 = pd.read_csv('User1.csv', index_col=0)\n",
    "data2['SPENT'] = 0\n",
    "#data = data.combine_first(data2).fillna(0) #method='ffill'\n",
    "data = pd.merge(left=data, right=data2, on=['WEEKIND', 'YEARIND'], how='outer')\n",
    "data['SPENT2'] = data.SPENT_x + data.SPENT_y\n",
    "data.SPENT2 = data.SPENT2.fillna(0)\n",
    "data = data.fillna(method='ffill')\n",
    "print(data)\n",
    "data.to_csv('User2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEAL_CODE  ACCOUNT_CODE  COUPON_CODE\n",
      "20         200           100            90\n",
      "           10869649      2158           90\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data2 = pd.read_csv('User1.csv', index_col=0)\n",
    "data2['SPENT'] = 0\n",
    "data = pd.read_csv('User10869649.csv', index_col=0).reset_index(drop=True)\n",
    "\n",
    "def f(group):\n",
    "   test = pd.merge(left=group.reset_index(), right=data2, on=['WEEKIND', 'YEARIND'], how='outer')\n",
    "   test['SPENT2'] = test.SPENT_x + test.SPENT_y\n",
    "   test.SPENT2 = test.SPENT2.fillna(0)\n",
    "   test = test.fillna(method='ffill')\n",
    "   #print(test)\n",
    "   return group.SPENT.min()\n",
    "\n",
    "\n",
    "grouped = data.groupby(['DEAL_CODE', 'ACCOUNT_CODE', 'COUPON_CODE']).apply(f)\n",
    "print(grouped)\n",
    "grouped[20, 200, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def initial_trend(series, slen):\n",
    "    sum = 0.0\n",
    "    for i in range(slen):\n",
    "        sum += float(series.iloc[i+slen] - series.iloc[i]) / slen\n",
    "    return sum / slen\n",
    "\n",
    "def initial_seasonal_components(series, slen):\n",
    "    seasonals = {}\n",
    "    season_averages = []\n",
    "    n_seasons = int(len(series)/slen) \n",
    "    # compute season averages\n",
    "    for j in range(n_seasons):\n",
    "        season_averages.append(sum(series.compute()[slen*j:slen*j+slen])/float(slen))\n",
    "        #season_averages.append(1)\n",
    "        #print(season_averages[0])\n",
    "    #print('n_seasons: ', n_seasons, ' season_averages len: ', len(season_averages))\n",
    "    # compute initial values\n",
    "    for i in range(slen):\n",
    "        sum_of_vals_over_avg = 0.0\n",
    "        for j in range(n_seasons):\n",
    "            #print(series.compute().iloc[0])\n",
    "            sum_of_vals_over_avg += series.compute().iloc[slen*j+i]-season_averages[j]\n",
    "        seasonals[i] = sum_of_vals_over_avg/n_seasons\n",
    "    return seasonals\n",
    "\n",
    "def triple_exponential_smoothing(series, slen=4, alpha=0.716, beta=0.029, gamma=0.993, n_preds=1):\n",
    "    result = []\n",
    "    seasonals = initial_seasonal_components(series, slen)\n",
    "    for i in range(len(series)+n_preds):\n",
    "        if i == 0: # initial values\n",
    "            smooth = series.compute().iloc[0]\n",
    "            trend = initial_trend(series.compute(), slen)\n",
    "            result.append(series.compute().iloc[0])\n",
    "            continue\n",
    "        if i >= len(series): # we are forecasting\n",
    "            m = i - len(series) + 1\n",
    "            result.append((smooth + m*trend) + seasonals[i%slen])\n",
    "        else:\n",
    "            val = series.compute().iloc[i]\n",
    "            last_smooth, smooth = smooth, alpha*(val-seasonals[i%slen]) + (1-alpha)*(smooth+trend)\n",
    "            trend = beta * (smooth-last_smooth) + (1-beta)*trend\n",
    "            seasonals[i%slen] = gamma*(val-smooth) + (1-gamma)*seasonals[i%slen]\n",
    "            result.append(smooth+trend+seasonals[i%slen])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data2 = pd.read_csv('User1.csv', index_col=0)\n",
    "data2['SPENT'] = 0\n",
    "#data = pd.read_csv('c:/Users/dani/PycharmProjects/WOW/CSV/TCUSTCOUPONITEMSSPENT.csv', index_col=None).reset_index(drop=True)\n",
    "data = pd.read_csv('User10869649.csv', index_col=0).reset_index(drop=True)\n",
    "\n",
    "def f(group):\n",
    "   df = pd.merge(left=group.reset_index(), right=data2, on=['WEEKIND', 'YEARIND'], how='outer')\n",
    "   df['SPENT2'] = df.SPENT_x + df.SPENT_y\n",
    "   df.SPENT2 = df.SPENT2.fillna(0)\n",
    "   df['DATE'] = 100*df.YEARIND + df.WEEKIND\n",
    "   df.sort_values(['DATE'], inplace=True)\n",
    "   df = df.fillna(method='ffill')\n",
    "   df = df.dropna()\n",
    "   df = df.reset_index()\n",
    "   hws = triple_exponential_smoothing(df.SPENT2)\n",
    "   #df.to_csv('User.csv')\n",
    "   return hws[-1] #group.SPENT.min()\n",
    "\n",
    "grouped = data.groupby(['DEAL_CODE', 'ACCOUNT_CODE', 'COUPON_CODE']).apply(f)\n",
    "#grouped.to_csv('c:/Users/dani/PycharmProjects/WOW/CSV/TCUSTCOUPONITEMSSPENT_predicted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false,
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DEAL_CODE  ACCOUNT_CODE  COUPON_CODE  SPENT  WEEKIND  YEARIND\n",
      "0         20          3597         2123    510       39       16\n",
      "1         20          3597         2123    510       44       16\n",
      "2         20          3597         2159    330       52       16\n",
      "3         20          3597         2140    600       13       17\n",
      "4         20          3597         2140    636       20       17\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-289-dae6b8e43034>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[1;31m#print(grouped.compute())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[1;31m#grouped.visualize()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mgrouped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'testgroup'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[1;31m#grouped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[1;31m#grouped.where(grouped>200)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda\\lib\\site-packages\\dask\\dataframe\\core.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, filename, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_delayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[1;34m\"\"\" See dd.to_delayed docstring for more information \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda\\lib\\site-packages\\dask\\dataframe\\io\\csv.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(df, filename, name_function, compression, compute, get, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0mquotechar\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mstring\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[1;34m'\\\"'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0mcharacter\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mquote\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0mdoublequote\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mboolean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0mControl\u001b[0m \u001b[0mquoting\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mquotechar\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minside\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0mescapechar\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mstring\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda\\lib\\site-packages\\dask\\base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mExtra\u001b[0m \u001b[0mkeywords\u001b[0m \u001b[0mto\u001b[0m \u001b[0mforward\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mget\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \"\"\"\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda\\lib\\site-packages\\dask\\base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0mdsk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections_to_dsk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimize_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda\\lib\\site-packages\\dask\\threaded.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, result, cache, num_workers, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     results = get_async(pool.apply_async, len(pool._pool), dsk, result,\n\u001b[1;32m     74\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_thread_get_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                         pack_exception=pack_exception, **kwargs)\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[1;31m# Cleanup pools associated to dead threads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda\\lib\\site-packages\\dask\\local.py\u001b[0m in \u001b[0;36mget_async\u001b[0;34m(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[1;31m# Main loop, wait on tasks to finish, insert new ones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'waiting'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ready'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'running'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                 \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfailed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mexc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda\\lib\\site-packages\\dask\\local.py\u001b[0m in \u001b[0;36mqueue_get\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "data2 = dd.read_csv('User1.csv')\n",
    "data2['SPENT'] = 0\n",
    "data = dd.read_csv('TCUST.csv')\n",
    "#data = dd.read_csv('User10869649.csv')\n",
    "print(data.head())\n",
    "\n",
    "def f(group):\n",
    "   df = dd.merge(left=group.reset_index(), right=data2, on=['WEEKIND', 'YEARIND'], how='outer')\n",
    "   df['SPENT2'] = df.SPENT_x + df.SPENT_y\n",
    "   df.SPENT2 = df.SPENT2.fillna(0)\n",
    "   df['DATE'] = 100*df.YEARIND + df.WEEKIND\n",
    "   #df.sort_values(['DATE'], inplace=True) # Dask dataframe doens't support sort_values()\n",
    "   df = df.fillna(method='ffill')\n",
    "   df = df.dropna()\n",
    "   df = df.set_index('DATE')\n",
    "   #print(df.SPENT2.compute().size)\n",
    "   hws = triple_exponential_smoothing(df.SPENT2)\n",
    "   return hws[-1]\n",
    "\n",
    "#group_result = pd.DataFrame(columns=['DEAL_CODE', 'ACCOUNT_CODE', 'COUPON_CODE', 'VALUE'])\n",
    "series_result = pd.Series()\n",
    "grouped = data.groupby(['DEAL_CODE', 'ACCOUNT_CODE', 'COUPON_CODE']).apply(f, meta=series_result)\n",
    "#type(grouped)\n",
    "#len(grouped)\n",
    "#print(grouped.compute())\n",
    "#grouped.visualize()\n",
    "grouped.to_csv('testgroup')\n",
    "#grouped\n",
    "#grouped.where(grouped>200)\n",
    "#grouped[20, 200, 100] not working\n",
    "#for group in grouped:\n",
    "#    print (grouped.get_group(group))\n",
    "#grouped.values.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
