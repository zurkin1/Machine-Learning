{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 18 Demo: Modeling in time series in statsmodels (45 mins)\n",
    "\n",
    "To explore time series models, we will continue with the Rossmann sales data.  This dataset has sales data for every Rossmann store for a 3-year period, as well as indicators of holidays and basic store information.\n",
    "\n",
    "In the last class, we saw that we would plot the sales data at a particular store to identify how the sales changed over time.  Additionally, we computed autocorrelation for the data at varying lag periods. This helps us identify if previous timepoints are predictive of future data and which time points are most important - the previous day? week? month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "# Load the data and set the DateTime index\n",
    "data = pd.read_csv('../data/rossmann.csv', skipinitialspace=True, low_memory=False)\n",
    "\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter to Store 1\n",
    "store1_data = data[data.Store == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter to open days\n",
    "store1_open_data = store1_data[store1_data.Open==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the sales over time\n",
    "store1_open_data[['Sales']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check** Compute the autocorrelation of Sales in Store 1 for lag 1 and 2. Will we be able to use a predictive model - particularly an autoregressive one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print store1_data.Sales.autocorr(lag=1) # -0.12\n",
    "print store1_data.Sales.autocorr(lag=2) # -0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do see some minimal correlation in time, implying an AR model can be useful. An easier way to diagnose this may be to plot many autocorrelations at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pandas.tools.plotting import autocorrelation_plot\n",
    "autocorrelation_plot(store1_data.Sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows a typical pattern of an autocorrelation plot - it should decrease to 0 as lag increases! However, it's hard to observe exactly what the values are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `statsmodels` to code AR, MA, ARMA and ARIMA models.\n",
    "\n",
    "`statsmodels` is a machine learning package, similar to `sckit-learn`.  While it lacks many of the features of `scikit-learn` for evaluation and production level models, it does include many more niche statistical models, including time series models. It also provides a nice summary utility to help diagnose models.\n",
    "\n",
    "`statsmodels` also has a better autocorrelation plot, which can look at fixed numbers of lag values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plot_acf(store1_data.Sales, lags=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we observe autocorrelation at 10 lag values. 1 and 2 are what we saw before. This implies a small, but limited impact based on the last few values, suggesting that an autoregressive model might be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We also observe a larger spike at 7 - what does that mean?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we observed a handful of randomly distributed spikes - that would imply a MA model may be useful. This is because those random spikes suggest that at some point in time, something changed in the world and all values are shifted up down from there in a fixed way.\n",
    "\n",
    "That may be the case here, but if we expand the window we can see that the spikes occur regularly at 7 days windows. This means we have a weekly cycle!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_acf(store1_data.Sales, lags=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by investigating AR models.\n",
    "### AR, MA and ARMA models in Statsmodels\n",
    "\n",
    "To explore AR and ARMA models, we will use `sm.tsa.ARMA`. Remember, an ARMA model is a combination of autoregressive and moving average models.\n",
    "\n",
    "We can train an autoregressive model by turning off the moving average component (setting q = 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By passing the `(1, 0)` in the second argument, we are fitting an ARMA model as ARMA(p=1, q=1). Remember, an ARMA(p, q) model is AR(p) + MA(q). This means that an ARMA(1, 0) is the same as an AR(1) model.\n",
    "\n",
    "In this AR(1) model we learn an intercept value, or base sales values. Additionally, we learn a coefficient that tells us how to include the last sales values. In this case, we take the intercept of ~4700 and add in the previous months sales * 0.68.\n",
    "\n",
    "Note the coefficient here does not match the lag 1 autocorrelation - implying the the data is not stationary.\n",
    "\n",
    "We can learn an AR(2) model, which regresses each sales value on the last two, with the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARMA\n",
    "\n",
    "store1_sales_data = store1_open_data[['Sales']].astype(float)\n",
    "model = ARMA(store1_sales_data, (1, 0)).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ARMA(store1_sales_data, (2, 0)).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we learn two coefficients, which tells us the effect of the last two sales values on current sales. To make a sales prediction for a future month, we would combine the last two months of sales with the weights or coefficients learned.\n",
    "\n",
    "While this model may be able to better model the series, it may be more difficult to interpret.\n",
    "\n",
    "To start to diagnose the model, we want to look at the _residuals_.\n",
    "\n",
    "**Check:** What are residuals? In linear regression, what did we expect of residuals?\n",
    "\n",
    "_Residuals_ are the errors of the model, or a measure of how off our prior predictions were.\n",
    "\n",
    "What we ideally want are randomly distributed errors that are fairly small. If the errors are large then clearly that would be problematic. If the errors have a pattern, particularly over time, then we have overlooked something in the model or certain periods of time are different than the rest of the dataset.\n",
    "\n",
    "We can plot the residuals as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.resid.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we saw large spikes at the end of each year, indicating that our model does not account for holiday spikes. Of course, our models are only related to the last few values in the time series, and don't take into account the longer seasonal pattern.\n",
    "\n",
    "We can also plot the autocorrelations of the residuals. In an ideal model, these would all nearly be 0 and hopefully random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_acf(model.resid, lags=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This aspect is also troubling - the autocorrelation plot shows a clear pattern where errors are increasing and decreasing every week.\n",
    "\n",
    "To expand this AR model to a ARMA model, we can include the moving average component as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ARMA(store1_sales_data, (1, 1)).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we learn two coefficients, one for the AR(1) component and one for the MA(1)\n",
    "\n",
    "**Check:** Take a moment to look at the coefficients and offer an interpretation.\n",
    "\n",
    "Remember this is an AR(1) + MA(1) model. So the AR coefficient represents dependency on the last value and the MA component represents any spikes independent of the last value.\n",
    "\n",
    "The coefficients here are 0.69 for the AR component and -0.03 for the MA component. The AR coefficient is the same as before (decreasing values) and the MA component is fairly small (which we should have expected from the autocorrelation plots).\n",
    "\n",
    "### ARIMA models in Statsmodels\n",
    "\n",
    "To train an ARIMA model in `statsmodels`, we can change the `ARMA` model to `ARIMA` and additionally provide the differencing parameter. To start, we can see that we can train an ARMA(2,2) model by training an ARIMA(2, 0, 2) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ARIMA(store1_sales_data, (2, 1, 2)).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For a moment, let's remove the moving average component since it wasn't particularly useful before.\n",
    "model = ARIMA(store1_sales_data, (2, 1, 0)).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is now an AR(1) model on the differenced data.  We learn a single coefficient of -.18.\n",
    "\n",
    "**Check:** Does this match the lag 1 autocorrelation of the differenced series? Is the data stationary?\n",
    "\n",
    "Yes, we can compute the lag 1 auto correlation of the difference series and see if they match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store1_sales_data.Sales.diff(1).autocorr(1) #-0.181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can plot it to see the difference.\n",
    "store1_sales_data.Sales.diff(1).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check**: Notice this looks generally true, but the variance is not constant. Why not?\n",
    "\n",
    "> Answer: It is mostly the same throughout the series except around the holidays.\n",
    "\n",
    "From our models, we can also plot future predictions and compare them with the true series. To compare our forecast with the true values, we can use the `plot_predict` function.\n",
    "\n",
    "We can compare the last 50 days of true values and predictions as values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.predict(1, 50).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes two arguments which are the start and end index of the dataframe to plot. Here, we are plotting the last 50 values.\n",
    "\n",
    "To plot earlier values, with our predictions extended out, we do the following. This plots true values in 2014, and our predictions 200 days out from 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = store1_sales_data['2014'].plot(ax=ax)\n",
    "\n",
    "fig = model.plot_predict(1, 200, ax=ax, plot_insample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can revisit our diagnostics to check if our models are working well.\n",
    "\n",
    "**Check:** Plot the residuals and autocorrelation of residuals to test that model is working well. Are there patterns or outliers?\n",
    "\n",
    "The two previous problems remain: large errors around the holiday period and these errors have high autocorrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can alter the AR model to adjust for a piece of this - increasing the lag to 7.\n",
    "\n",
    "model = ARIMA(store1_sales_data, (7, 1, 2)).fit()\n",
    "model.summary()\n",
    "\n",
    "plot_acf(model.resid, lags=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This removes some of the autocorrelation in the residuals, but large discrepancies still exist. However, they exist where we are breaking our model assumptions as well, which is important to keep in mind.\n",
    "\n",
    "**Check:** Alter the time period of predictions and p, d, q parameters. Do any of these improve the diagnostics? What does changing p and q imply based on the autocorrelation plot? How about d?\n",
    "\n",
    "After some practice with altering p, q, d - there aren't many models that fix the issue left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Increasing p would increase the dependency on previous values further (longer lag), but this isn't necessary past a given point.\n",
    "- Increasing q would increase the dependency of an unexpected jump at a handful of points, but we did not observe that in our autocorrelation plot.\n",
    "- Increasing d would increase differencing, but with d=1 we saw a move towards stationarity already (except at a few problematic regions). Increasing to 2 may be useful if we are saw an exponential trend, but that we did not here.\n",
    "\n",
    "There are variants of ARIMA that will handle the seasonal aspect better, known as Seasonal ARIMA. In short, these models fit two ARIMA models, one of the daily frequency and another on the seasonal frequency (monthly or yearly, whichever the pattern may be).\n",
    "\n",
    "Issues with seasonality could also be handled by pre-processing tricks such as detrending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
