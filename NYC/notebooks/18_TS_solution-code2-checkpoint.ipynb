{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walmart Sales Data\n",
    "\n",
    "For the independent practice, we will analyze the weekly sales data from Walmart over a two year period from 2010 to 2012.\n",
    "\n",
    "The data is again separated by store and by department, but we will focus on analyzing one store for simplicity.\n",
    "\n",
    "The data includes:\n",
    "\n",
    "- Store - the store number\n",
    "- Dept - the department number\n",
    "- Date - the week\n",
    "- Weekly_Sales -  sales for the given department in the given store\n",
    "- IsHoliday - whether the week is a special holiday week\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data and setting the DateTimeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/JamesByers/GA-SEA-DAT2/master/data/time_series_train.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter the dataframe to Store 1 sales and aggregate over departments to compute the total sales per store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter to store 1 sales and average over weeks\n",
    "store1_sales = data[data.Store == 1][['Weekly_Sales']].resample('W', 'sum')\n",
    "store1_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the rolling_mean for `Weekly_Sales`. What general trends do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.rolling_mean(store1_sales[['Weekly_Sales']], 3).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Compute the 1, 2, 52 autocorrelations for `Weekly_Sales` and/or create an autocorrelation plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Autocorrelation 1: ', store1_sales['Weekly_Sales'].autocorr(1))\n",
    "print('Autocorrelation 3: ', store1_sales['Weekly_Sales'].autocorr(3))\n",
    "print('Autocorrelation 52: ', store1_sales['Weekly_Sales'].autocorr(52))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import autocorrelation_plot\n",
    "\n",
    "autocorrelation_plot(store1_sales['Weekly_Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "plot_acf(store1_sales['Weekly_Sales'], lags=30)\n",
    "\n",
    "# Components 1 and 2 seem particularly useful for autoregression, perhaps up to 4\n",
    "# In the plot above notice, spike at around 52 - implying a yearly pattern as well\n",
    "# No random spikes, probably not much use for a moving average model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the weekly sales data in a training and test set - using 75% of the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(store1_sales.Weekly_Sales)\n",
    "\n",
    "train = store1_sales.Weekly_Sales[:int(.75*n)]\n",
    "test = store1_sales.Weekly_Sales[int(.75*n):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an AR(1) model on the training data and compute the mean absolute error of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = sm.tsa.ARIMA(train, (1, 0, 0)).fit()\n",
    "\n",
    "predictions = model.predict(\n",
    "    '2012-02-27',\n",
    "    '2012-10-29',\n",
    "    dynamic=True, \n",
    ")\n",
    "\n",
    "print(\"Mean absolute error: \", mean_absolute_error(test, predictions))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the residuals - where are their significant errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.resid.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_acf(model.resid, lags=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute and AR(2) model and an ARMA(2, 2) model - does this improve your mean absolute error on the held out set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = sm.tsa.ARIMA(train, (2, 0, 0)).fit()\n",
    "\n",
    "predictions = model.predict(\n",
    "    '2012-02-27',\n",
    "    '2012-10-29',\n",
    "    dynamic=True, \n",
    ")\n",
    "\n",
    "print(\"Mean absolute error: \", mean_absolute_error(test, predictions))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = sm.tsa.ARIMA(train, (2, 0, 2)).fit()\n",
    "\n",
    "predictions = model.predict(\n",
    "    '2012-02-27',\n",
    "    '2012-10-29',\n",
    "    dynamic=True, \n",
    ")\n",
    "\n",
    "print(\"Mean absolute error: \", mean_absolute_error(test, predictions))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, compute an ARIMA model to improve your prediction error - iterate on the p, q, and parameters comparing the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = sm.tsa.ARIMA(train, (2, 1, 3)).fit()\n",
    "\n",
    "predictions = model.predict(\n",
    "    '2012-02-27',\n",
    "    '2012-10-29',\n",
    "    dynamic=False, \n",
    "    typ='levels'\n",
    ")\n",
    "\n",
    "print(\"Mean absolute error: \", mean_absolute_error(test, predictions))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
